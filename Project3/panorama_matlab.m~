%% MATLAB oriented



% Load Images
filePath = '/home/pari/Desktop/Courses/Vision/Project3/image_data';
buildingScene = imageSet(filePath);

% Read the first image from the image set.
I = read(buildingScene, 1);

% Initialize features for I(1)
I_gray = double(I_gray);

[numR, numC] = size(I_gray);

% get the corners before ANMS
C_mag = cornermetric(im2double(rgb2gray(I)));

% params
NUM_PTS_REQD = 300;

% for every pixel, calc minR - mainly for visualising
minR_mat = 0.*ones(size(I_gray,1), size(I_gray,2));

% perform anms
[im1_corn_c, im1_corn_r, ~ ] = anms(C_mag,NUM_PTS_REQD);
im1_filteredPts = sub2ind([numR, numC], im1_corn_r,im1_corn_c);

% extract feature descriptors
im1_desc_linear = feat_desc(I_gray, im1_corn_r, im1_corn_c);
[im1_filterPts_cartesian(:,1),im1_filterPts_cartesian(:,2)] = ind2sub([numR, numC], im1_filteredPts);

% Initialize all the transforms to the identity matrix. Note that the
% projective transform is used here because the building images are fairly
% close to the camera. Had the scene been captured from a further distance,
% an affine transform would suffice.
tforms(buildingScene.Count) = projective2d(eye(3));

points = 

% Iterate over remaining image pairs
for n = 2:buildingScene.Count

    % Store points and features for I(n-1).
    pointsPrevious = points;
    featuresPrevious = features;

    % Read I(n).
    I = read(buildingScene, n);

    % Detect and extract SURF features for I(n).
   C_mag = cornermetric(im2double(rgb2gray(I)));

   % for every pixel, calc minR - mainly for visualising
   minR_mat = 0.*ones(size(I_gray,1), size(I_gray,2));
   
   % perform anms
   [im2_corn_c, im2_corn_r, ~ ] = anms(C_mag,NUM_PTS_REQD);
   im2_filteredPts = sub2ind([numR, numC], im2_corn_r,im2_corn_c);
   
   % compare the points
   %visualizeFeatures(I1, im1_filteredPts, I2, im2_filteredPts);
   
  
   % extract feature descriptors
   im2_desc_linear = feat_desc(I_gray, im2_corn_r, im2_corn_c);
   [im2_filterPts_cartesian(:,1),im2_filterPts_cartesian(:,2)] = ind2sub([numR, numC], im2_filteredPts);


    % Find correspondences between I(n) and I(n-1).
   match_results = feat_match(im1_desc_linear, im2_desc_linear);

   % filter match_results
   valid_matches = find(match_results > -1);
   
   mappedTo_idx = im2_filteredPts(match_results(valid_matches));
   [mappedTo_cart(:,1), mappedTo_cart(:,2)] = ind2sub([numR, numC], mappedTo_idx);


    % Estimate the transformation between I(n) and I(n-1).


    % Compute T(1) * ... * T(n-1) * T(n)
    tforms(n).T = tforms(n-1).T * tforms(n).T;
end

imageSize = size(I);  % all the images are the same size

% Compute the output limits  for each transform
for i = 1:numel(tforms)
    [xlim(i,:), ylim(i,:)] = outputLimits(tforms(i), [1 imageSize(2)], [1 imageSize(1)]);
end

avgXLim = mean(xlim, 2);

[~, idx] = sort(avgXLim);

centerIdx = floor((numel(tforms)+1)/2);

centerImageIdx = idx(centerIdx);


for i = 1:numel(tforms)
    [xlim(i,:), ylim(i,:)] = outputLimits(tforms(i), [1 imageSize(2)], [1 imageSize(1)]);
end

% Find the minimum and maximum output limits
xMin = min([1; xlim(:)]);
xMax = max([imageSize(2); xlim(:)]);

yMin = min([1; ylim(:)]);
yMax = max([imageSize(1); ylim(:)]);

% Width and height of panorama.
width  = round(xMax - xMin);
height = round(yMax - yMin);

% Initialize the "empty" panorama.
panorama = zeros([height width 3], 'like', I);


blender = vision.AlphaBlender('Operation', 'Binary mask', ...
    'MaskSource', 'Input port');

% Create a 2-D spatial reference object defining the size of the panorama.
xLimits = [xMin xMax];
yLimits = [yMin yMax];
panoramaView = imref2d([height width], xLimits, yLimits);

% Create the panorama.
for i = 1:buildingScene.Count

    I = read(buildingScene, i);

    % Transform I into the panorama.
    warpedImage = imwarp(I, tforms(i), 'OutputView', panoramaView);

    % Overlay the warpedImage onto the panorama.
    panorama = step(blender, panorama, warpedImage, warpedImage(:,:,1));
end

figure
imshow(panorama)